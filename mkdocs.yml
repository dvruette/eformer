nav:
  - Bits:
    - Bits: generated-bits-bits.md
    - Calibration: generated-bits-calibration.md
    - Config: generated-bits-config.md
    - Int Numerics: generated-bits-int_numerics.md
    - No Numerics: generated-bits-no_numerics.md
    - Numerics: generated-bits-numerics.md
    - Q Dot General: generated-bits-q_dot_general.md
    - Q Flax: generated-bits-q_flax.md
    - Qk: generated-bits-qk.md
    - Stochastic Rounding: generated-bits-stochastic_rounding.md
  - Checkpoint:
    - Load: generated-checkpoint-_load.md
    - Streamer: generated-checkpoint-streamer.md
  - Functions:
    - Func: generated-functions-_func.md
    - Loss Func: generated-functions-loss_func.md
  - Home: index.md
  - Linen:
    - Linen: generated-linen-linen.md
  - Monitor:
    - Tracker: generated-monitor-tracker.md
  - Optimizers:
    - Adafactor: generated-optimizers-adafactor.md
    - Adamw: generated-optimizers-adamw.md
    - Lion: generated-optimizers-lion.md
    - Optimizer Utils: generated-optimizers-optimizer_utils.md
    - Rmsprop: generated-optimizers-rmsprop.md
  - Pallas Operations:
    - Efficient Attention:
      - Efficient Attention: generated-pallas_operations-efficient_attention-efficient_attention.md
    - Layer Norm:
      - Gpu:
        - Layer Norm: generated-pallas_operations-layer_norm-gpu-layer_norm.md
    - Pallas Flash Attention:
      - Attention: generated-pallas_operations-pallas_flash_attention-attention.md
    - Ring Attention:
      - Ring Attention: generated-pallas_operations-ring_attention-ring_attention.md
    - Rms Norm:
      - Gpu:
        - Rms Norm: generated-pallas_operations-rms_norm-gpu-rms_norm.md
    - Softmax:
      - Gpu:
        - Softmax: generated-pallas_operations-softmax-gpu-softmax.md
    - Splash Attention:
      - Tpu:
        - Splash Attention Kernel: generated-pallas_operations-splash_attention-tpu-splash_attention_kernel.md
        - Splash Attention Mask: generated-pallas_operations-splash_attention-tpu-splash_attention_mask.md
        - Splash Attention Mask Info: generated-pallas_operations-splash_attention-tpu-splash_attention_mask_info.md
    - Tpu Flash Attention:
      - Gpu:
        - Jax Flash Attn Gpu: generated-pallas_operations-tpu_flash_attention-gpu-jax_flash_attn_gpu.md
      - Tpu:
        - Jax Flash Attn Tpu: generated-pallas_operations-tpu_flash_attention-tpu-jax_flash_attn_tpu.md
  - Sharding:
    - Sharding: generated-sharding-sharding.md
    - T5x Partitioning: generated-sharding-t5x_partitioning.md
  - Utils: generated-utils.md
  - Xrapture:
    - Implicit Array: generated-xrapture-implicit_array.md
    - Tracer: generated-xrapture-tracer.md
    - Xrapture: generated-xrapture-xrapture.md

plugins:
  - search
  - mkdocstrings:
      handlers:
        python:
          options:
            docstring_style: sphinx

repo_url: https://github.com/erfanzar/FJFormer
site_author: Erfan Zare Chavoshi
site_name: FJFormer
copyright: Erfan Zare Chavoshi-FJFormer

theme:
  highlightjs: true
  hljs_languages:
    - yaml
    - python
  name: material
